{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required modules\n",
    "import numpy as np\n",
    "import pydotplus\n",
    "import pandas as pd\n",
    "import sklearn.datasets as Datasets\n",
    "from sklearn import tree\n",
    "from sklearn import model_selection as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying Iris Dataset to change it to Labeled DataÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert continuous data to discrete values\n",
    "def makeLabelled(column):\n",
    "    mean = column.mean()\n",
    "    for i in range (0,len(column)):\n",
    "        column[i] = int(column[i]>=mean) \n",
    "    return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = Datasets.load_iris()\n",
    "df = pd.DataFrame(iris.data)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.values\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting data to labelled form\n",
    "for i in range(0,X.shape[-1]):\n",
    "    X[:,i] = makeLabelled(X[:,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculates entropy\n",
    "def entropy(Y):\n",
    "    classes = set(Y)\n",
    "    value = 0\n",
    "    for i in classes:\n",
    "        p = (len(Y[Y==i])/len(Y))\n",
    "        value = value - (p*np.log2(p))\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find gain ration for a selected feature\n",
    "def CalcGainRatio(X, Y, selectedFeature):\n",
    "    differentLabels = set(X[:, selectedFeature])\n",
    "    entropyBeforeSplitting = entropy(Y)\n",
    "    entropyAfterSplitting = 0\n",
    "    splitInfo = 0\n",
    "    for i in differentLabels:\n",
    "        newNodeY = Y[(X[:,selectedFeature] == i)]\n",
    "        weightOfSamples = (len(newNodeY)/len(Y))\n",
    "        entropyAfterSplitting = entropyAfterSplitting + (weightOfSamples*entropy(newNodeY))\n",
    "        splitInfo = splitInfo - (weightOfSamples*np.log2(weightOfSamples))\n",
    "    gain = entropyBeforeSplitting - entropyAfterSplitting\n",
    "    gainRatio = gain\n",
    "    return gainRatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to print count of classes\n",
    "def printClassCount(Y):\n",
    "    classes = set(Y)\n",
    "    for i in classes:\n",
    "        print(\"Count of \",i,\" = \",len(Y[Y==i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to print nodes of decision tree\n",
    "def decisionTree(X, Y, available_features):\n",
    "    print(\" \")\n",
    "    printClassCount(Y)\n",
    "    print(\"Current Entropy is = \",entropy(Y))\n",
    "    if(available_features == 0 or (entropy(Y) == 0)):\n",
    "        print(\"Reached leaf Node\")\n",
    "        return\n",
    "    selectedFeature = 0\n",
    "    max_value = -float('inf')\n",
    "    \n",
    "    # finding gain ratio for all possible features on which we can split and then choosing the feature with maximum gain.\n",
    "    for i in range(0,X.shape[-1]):\n",
    "        value = CalcGainRatio(X, Y, i)\n",
    "        if(value >= max_value):\n",
    "            selectedFeature = i\n",
    "            max_value = value\n",
    "    print(\"Splitting on feature \", selectedFeature)\n",
    "    \n",
    "    # find all possible unique labels for the selected feature.\n",
    "    differentLabels = set(X[:, selectedFeature])\n",
    "    for i in differentLabels:\n",
    "        newDataSamples = (X[:, selectedFeature] == i)\n",
    "        newX = X[newDataSamples]\n",
    "        newY = Y[newDataSamples]\n",
    "        decisionTree(newX, newY, available_features - 1)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying descision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Count of  0  =  1\n",
      "Count of  1  =  3\n",
      "Current Entropy is =  0.8112781244591328\n",
      "Splitting on feature  1\n",
      " \n",
      "Count of  0  =  1\n",
      "Count of  1  =  1\n",
      "Current Entropy is =  1.0\n",
      "Splitting on feature  0\n",
      " \n",
      "Count of  0  =  1\n",
      "Current Entropy is =  0.0\n",
      "Reached leaf Node\n",
      " \n",
      "Count of  1  =  1\n",
      "Current Entropy is =  0.0\n",
      "Reached leaf Node\n",
      " \n",
      "Count of  1  =  2\n",
      "Current Entropy is =  0.0\n",
      "Reached leaf Node\n"
     ]
    }
   ],
   "source": [
    "# testing on OR dataset\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "Y = np.array([0,1,1,1])\n",
    "decisionTree(X,Y,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Count of  0  =  1\n",
      "Count of  1  =  3\n",
      "Current Entropy is =  0.8112781244591328\n",
      "Splitting on feature  1\n",
      " \n",
      "Count of  0  =  1\n",
      "Count of  1  =  1\n",
      "Current Entropy is =  1.0\n",
      "Splitting on feature  0\n",
      " \n",
      "Count of  0  =  1\n",
      "Current Entropy is =  0.0\n",
      "Reached leaf Node\n",
      " \n",
      "Count of  1  =  1\n",
      "Current Entropy is =  0.0\n",
      "Reached leaf Node\n",
      " \n",
      "Count of  1  =  2\n",
      "Current Entropy is =  0.0\n",
      "Reached leaf Node\n"
     ]
    }
   ],
   "source": [
    "# testing on iris dataset\n",
    "decisionTree(X,Y,4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
